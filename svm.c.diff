--- /arch/x86/kvm/svm/svm.c	2022-12-11 14:15:18
+++ ./svm.c	2023-04-08 05:25:47
@@ -1164,7 +1164,43 @@ static inline void init_vmcb_after_set_cpuid(struct kv
 		/* No need to intercept these MSRs */
 		set_msr_interception(vcpu, svm->msrpm, MSR_IA32_SYSENTER_EIP, 1, 1);
 		set_msr_interception(vcpu, svm->msrpm, MSR_IA32_SYSENTER_ESP, 1, 1);
+	}
+}
+
+static u32 print_once = 1;
+
+static int handle_rdtsc_interception(struct kvm_vcpu *vcpu) 
+{
+    	static u64 rdtsc_fake = 0;
+	static u64 rdtsc_prev = 0;
+	u64 rdtsc_real = rdtsc();
+
+	if(print_once)
+	{
+		printk("[handle_rdtsc] fake rdtsc svm function is working\n");
+		print_once = 0;
+		rdtsc_fake = rdtsc_real;
+	}
+
+	if(rdtsc_prev != 0)
+	{
+		if(rdtsc_real > rdtsc_prev)
+		{
+			u64 diff = rdtsc_real - rdtsc_prev;
+			u64 fake_diff =  diff / 20; // if you have 3.2Ghz on your vm, change 20 to 16
+			rdtsc_fake += fake_diff;
+		}
+	}
+	if(rdtsc_fake > rdtsc_real)
+	{
+		rdtsc_fake = rdtsc_real;
 	}
+	rdtsc_prev = rdtsc_real;
+
+	vcpu->arch.regs[VCPU_REGS_RAX] = rdtsc_fake & -1u;
+    	vcpu->arch.regs[VCPU_REGS_RDX] = (rdtsc_fake >> 32) & -1u;
+
+    	return svm_skip_emulated_instruction(vcpu);
 }
 
 static void init_vmcb(struct kvm_vcpu *vcpu)
@@ -1227,6 +1263,7 @@ static void init_vmcb(struct kvm_vcpu *vcpu)
 	svm_set_intercept(svm, INTERCEPT_XSETBV);
 	svm_set_intercept(svm, INTERCEPT_RDPRU);
 	svm_set_intercept(svm, INTERCEPT_RSM);
+    svm_set_intercept(svm, INTERCEPT_RDTSC);
 
 	if (!kvm_mwait_in_guest(vcpu->kvm)) {
 		svm_set_intercept(svm, INTERCEPT_MONITOR);
@@ -3201,6 +3238,7 @@ static int (*const svm_exit_handlers[])(struct kvm_vcp
 	[SVM_EXIT_AVIC_INCOMPLETE_IPI]		= avic_incomplete_ipi_interception,
 	[SVM_EXIT_AVIC_UNACCELERATED_ACCESS]	= avic_unaccelerated_access_interception,
 	[SVM_EXIT_VMGEXIT]			= sev_handle_vmgexit,
+    [SVM_EXIT_RDTSC]			= handle_rdtsc_interception,
 };
 
 static void dump_vmcb(struct kvm_vcpu *vcpu)
